{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "m0jC9tz1zQsd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_diabetes(return_X_y=True)"
      ],
      "metadata": {
        "id": "RPvMg8Ps3Js4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF82lMX63XAP",
        "outputId": "b774525f-a31c-45b9-eb53-5970a7bd7c1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "A_h-5T-J3cI9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a5AQ6CGShJ8J"
      },
      "outputs": [],
      "source": [
        "# Creating a custom class for Linear Regression using Gradient Descent\n",
        "class MBGDRegressor:\n",
        "\n",
        "    # Constructor to initialize learning rate and number of training epochs\n",
        "    def __init__(self,batch_size, learning_rate=0.01, epochs=100):\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.intercept_ = 0\n",
        "        self.coef_ = np.ones(X_train.shape[1])\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "          for j in range(int(X_train.shape[0] / self.batch_size)):\n",
        "\n",
        "            # generate random numbers based on the given range of batch size\n",
        "\n",
        "            idx = random.sample(range(X_train.shape[0]), self.batch_size)\n",
        "\n",
        "            y_hat = np.dot(X_train[idx], self.coef_) + self.intercept_\n",
        "            intercept_derivative = -2 * np.mean(y_train - y_hat)\n",
        "            self.intercept_ = self.intercept_ - (self.lr * intercept_derivative)\n",
        "\n",
        "            coef_derivative = -2 * np.dot((y_train[idx] - y_hat), X_train[idx])\n",
        "            self.coef_ = self.coef_ - (self.lr * coef_derivative)\n",
        "\n",
        "    # Predict method: used to predict outputs for test data\n",
        "    def predict(self, X_test):\n",
        "        # Prediction is the dot product of X and learned coefficients plus the intercept\n",
        "        return np.dot(X_test, self.coef_) + self.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdr = MBGDRegressor(batch_size = int(X_train.shape[0]/10), learning_rate = 0.01, epochs = 50)"
      ],
      "metadata": {
        "id": "J-AxsuxbxokB"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}